\chapter{Materials and Methods}\label{chap:methods}
The challenges in genomic analysis of viral material using \ac{NGS} raw read data are the major motivation for this thesis. Ready-to-use pipelines that can be executed without deeper biological or bioinformatic knowledge specifically designed for the viral genomes of avian influenza, pox and foot-and-mouth disease are presented below. They run on the Galaxy platform and show that for development of the pipelines, large parts of existing viral genomic analysis pipelines as such for SARS-CoV-2 can be reused and adapted.

\section{Galaxy Platform}\label{sec:galaxy}
Galaxy is a web-based scientific platform that has become a major player in many fields of life sciences and bioinformatics. Founded in 2007, it has provided an emerging amount of resources and tools to empower scientists and researchers to work with biomedical datasets. The platform is free to use and collaborative, as all related codebases are open-sourced on GitHub. Resources on Galaxy cover genomics, metagenomics, transcriptomics, proteomics, drug discovery and non-biology fields like natural language processing and social sciences.

Galaxy's primary objective is to make analyses more accessible, reproducible, and easier to communicate among researchers. The platform's distinctive and success is attributed to four core elements: a very active community, a public server for analyses, an open-source software ecosystem, and the Galaxy ToolShed. The community adheres to the FAIR practises (Findable, Accessible, Interoperable and Reusable)~\cite{10.1093/nar/gkac247}.

The Galaxy community is thriving, with over 124,000 users who also contribute to subcommunities. The public server for analyses provides access to public datasets and workflows. The open-source software ecosystem ensures automated setup and deployment of all tools and services, making it simple for beginners and professionals to use. The Galaxy ToolShed is a server dedicated to hosting, sharing, and installing tools used on the platform. A Galaxy tool is the abstraction layer that makes external software usable from within Galaxy with a front-end, i.e. lets users use the program with all its parameters and inputs from within Galaxy. Each program that is available as a Galaxy tool is XML-wrapped to make dependency requirements, parameter and data inputs and other settings possible via the Galaxy web-interface. \\ 
Galaxy workflows are a key feature that allow the user to stack tools in a chain and to configure them so that the workflow user only has to upload or enter data for the input fields. The automated subsequent order and execution of tools in a workflow is used for modular, longer analyses that are executed repeatedly. Each user gets 250 GB of disk space to run computations. \\
Workflows that are available on and accepted by the \ac{IWC} on GitHub are conform with the community's best practise standards and tested on the latest Galaxy release. Dockstore for availability in the U.S. and WorkflowHub for EU users publish the \ac{IWC} workflows and guarantee the availability in Docker-based environments and on the workflow collaborative WorkflowHub~\cite{o2017dockstore, goble2021implementing}.

Important contributions of Galaxy, as stated by the Galaxy Community (2022), include Vertebrate Genome Project assembly workflows and research collaborations about \ac{SARS-CoV-2}. Another toolkit leveraged in Galaxy is Galaxy-ML, a set of tools that form a suite for analyses based on machine learning. With growing publicity, more topics are covered by and moved to Galaxy. It has contributed to over 5,700 scientific publications and has many tutorials available for researchers to use. \\
The Galaxy platform is continuously enhanced, and it still attracts around 2,000 new users every month, indicating its quality and significance. The team and infrastructure of Galaxy initially come from the Nekrutenko lab in the Center for Comparative Genomics and Bioinformatics at Penn State, the Taylor lab at Johns Hopkins University, and the Goecks Lab at Oregon Health \& Science University. There are 138 public servers available worldwide as of 2023, while the most prominent general-purpose server instances are hosted by teams at University of Freiburg, Germany, for \href{https://usegalaxy.eu/}{UseGalaxy.eu}, Texas Advanced Computing Center for \href{https://usegalaxy.org/}{UseGalaxy.org} and Genomics Virtual Laboratory, formerly at the University of Queensland for \href{https://usegalaxy.org.au/}{UseGalaxy.org.au}. These public servers are synchronised in a set of reference tools~\cite{10.1093/nar/gkac247}. \\
The platform serves as a public infrastructure that can be used in many different contexts and by professionals from all fields and backgrounds. It therefore is very suitable for offering publicly available and transparent resources for surveillance of diseases.

\section{SARS-CoV-2 Workflow and Requirements}
The \ac{COVID-19} pandemic motivated many researchers to study and develop analysis workflows of \ac{SARS-CoV-2} sequencing data. In the \ac{IWC} repository, there are seven workflows available and ready to use on Galaxy for the different kind of \ac{NGS} data (ONT/Illumina) and with varying objectives (variant calling/variation reporting/consensus construction). Specifically for Illumina ARTIC reads, a workflow for genomic analysis based on the \texttt{iVar} suite has been released~\cite{iwc2021covidivar}. It is conceptually similar to other existing pipelines outside of Galaxy, written in Nextflow, Snakemake and \ac{WDL}. The workflow for ampliconic Illumina paired-end reads consists of the following steps: (1) read adapters are trimmed with \texttt{fastp} and (2) mapped to a reference genome with \texttt{BWA-MEM}. The alignment is (3) quality filtered using \texttt{Samtools view}, keeping the reads with a minimum length of 20 and only if they are mapped and properly paired. After generating quality and coverage reports, (4) \texttt{iVar trim} is run with the primer scheme to cut out the primers from the filtered alignment. The cleaned alignment file is processed (5) with \texttt{iVar consensus} to call the consensus sequence and (6) with \texttt{iVar variants} to call variants. The resulting outputs are used for variant annotation, phylogenetic assignment of the outbreak lineages and clade assignment. The structure of the workflow is depicted in~\figref{fig:3-sars-wf}. 

\begin{figure}[h!]
	\includegraphics[width=0.95\textwidth]{media/3-sars-cov-2.pdf}
	\caption{Simplified SARS-CoV-2 analysis workflow for ampliconic Illumina-sequenced data.}
	\label{fig:3-sars-wf}
\end{figure}

This workflow is designed for the specifics of the \ac{SARS-CoV-2} genome, however most viral genomes can be analysed in similar ways. Accounting for the genomic structure and composition of each virus, analysis workflows for poxviruses, avian influenza virus and foot-and-mouth disease virus are developed, reusing modified components of the described \ac{SARS-CoV-2} workflow. The requirements for the viruses and the workflows are described below, before the developed workflows are examined. %% more

\subsubsection{Requirements for Poxvirus Analysis Workflow}
As explained in~\secref{sec:2-pox}, the genome of most poxviruses is bound by identical sequences located at the termini of the genome. It is shown that the size of such differs for some poxviruses, such as rabbitpox and vaccinia virus, while mpox, cowpox and capripoxviruses have shorter \acp{ITR}~\cite{wittek1978inverted}. For a whole-genome reconstruction from \ac{HTS}-generated reads, alignment algorithms look for the unambiguous location of a read. Since this is impossible for repeated identical sequences neither for reference-based mapping approaches nor \textit{de novo} assembly, a new approach has to be used that splits the sequencing reads into two parts, separating the identical sequences and running alignment algorithms for each of the splits. To build the full-length genome, the alignments need to be ``glued'' together. This approach requires the reads to be sequenced in two pools with two libraries. A similar protocol has been described by Mathijs et al. and the ARTIC network for \ac{SARS-CoV-2} data~\cite{tyson2020improvements, mathijs2022robust}. \\
As a consequence, a requirement for a reference-based surveillance of the genomics of poxviruses is the availability of the primer scheme that was used for amplicon-based sequencing with an Illumina sequencer. The \ac{BED} file containing the primers, their positions and the pool identifier is essential for the correct linking of the alignments when splitting the pipeline into two parts and merging it back together. \\
Apart from the split approach with a masked reference sequence for alignment, the poxvirus reads can be processed in the same way as \ac{SARS-CoV-2} reads. In the \ac{SARS-CoV-2} workflow, clade and lineage assignment, with \texttt{Nextclade} and \texttt{Pangolin} respectively, work with \ac{SARS-CoV-2} specific databases. Although the tools are designed to work with the \ac{SARS-CoV-2} genome, the \texttt{Nextclade} tool is adapted and expanded to work with other viruses (mpox, Influenza A H1N1 and H3N2 HA gene, Influenza B Victoria and Yamagata HA)~\cite{aksamentov2021nextclade}.

\subsubsection{Requirements for AIV Analysis Workflow}
The main objectives of surveillance of \ac{AIV} on the genetic level are to get phylogenetic insights and to check for new variants that could occur in the \ac{HA} and \ac{NA} proteins as a consequence of reassortment. \\
A pipeline for an avian influenza virus sample that should build a consensus sequence in order to check for mutations needs a reference sequence that it can align the sequence to. A main caveat of many existing pipelines is the user's choice of reference sequence, since it is an arbitrary selection, and has a direct impact on the alignment. A reference is needed if the reads are aligned by mapping to this reference, while another, computationally very expensive approach would be assembly. Since the influenza segments can have very similar regions at the segment's ends and mapping is much faster, a reference-guided mapping method is favoured for the analysis of \ac{AIV} samples. The goal is to choose a reference that is representative of the sample being analysed. In the \ac{SARS-CoV-2} pipeline, a reference genome is recommended from a recent strain. For avian influenza virus, multiple reference sequences exist depending on the strain and subtype. Hence, a dynamic approach that is sensitive enough for the segmented structure of the \ac{AIV} genome is needed to pick a representative reference. The diversity of \ac{HA} and \ac{NA} segments' sequences is significant enough to make it challenging to map sequenced reads to a single, full-length influenza A reference sequence. Although this approach may be effective for the other six segments, the mapping software would frequently be unable to achieve sufficiently plausible matches for sequenced reads of \ac{HA} and \ac{NA} segments to continue with the analysis. By using a split approach that finds the best reference sequence from a database before the actual alignment, the expensive assembly step is avoided, the user is not required to choose an arbitrary reference and mapping to a suitable reference with minimal bias can finally be performed. \\
Compared to analyses with genomes such as \ac{SARS-CoV-2} and due to the segmented structure of the \ac{AIV} genome, duplicates among the mapped reads of the \ac{AIV} sample should not be dismissed but kept for maintaining a reasonable high coverage for the further analyses. Downstream analyses for phylogenetic placing are useful for the \ac{HA} and \ac{NA} genes, as well as visual summaries of \acp{SNP} to identify genetic variation in different regions.

\subsubsection{Requirements for FMDV Analysis Workflow}
Genomic analysis of the \ac{FMDV} viral \ac{RNA} genome requires a workflow that accounts for its high mutation rate. Finding a representative reference sequence from a database as it is done in the \ac{AIV} workflow with \texttt{VAPOR}, for \ac{FMDV} reads this approach would regularly fail due to the large differences between the query reads and the database sequences. Therefore, a different approach to find a suitable reference sequence for mapping is required. Since the \ac{FMDV} viral genome is relatively short with approximately 8.3 kilobases, a \textit{de novo} assembly takes only little amount of computational resources for a run. An assembly with a subsequent \ac{BLAST}n search in the nucleotides database is one method to find similar sequences that allow for a high-quality mapping.\\
Additionally, the workflow should include steps for quality control, including the removal of low-quality reads and the identification and removal of potential contaminants or other sources of error. Finally, the workflow should accommodate Illumina-sequenced data and be able to scale up for working with multiple samples at a time.

\section{Workflow Development}
Galaxy workflows developed for poxviruses, \ac{AIV} and \ac{FMDV} that account for the genomic structure of each virus and the \ac{NGS} approaches are described below.

\subsection{Poxvirus Illumina Amplicon Workflow}\label{sec:pox-wf}
The proposed Galaxy workflow for poxvirus samples that were Illumina-sequenced with a tiling amplicon approach is available on WorkflowHub, Dockstore and on \ac{IWC} to use on Galaxy EU (links in Supplementary~\secref{sec:apx-pox-links}). \\
This workflow is the first public pipeline for ampliconic Illumina-sequenced data that provides a ready-to-use infrastructure for genomic analysis of poxviruses with a tiled amplicon approach. It aims at constructing the full genome from ampliconic Illumina-sequenced reads and providing alignment files, sample-specific consensus sequence and intermediate results and reports that give insights into reads, mapping quality and mapping coverage. %An overview of all steps, these outputs and the respective datatypes in \ac{CWL} \todo{?} is provided in the Supplementary~\secref{sec:apx-pox-wf}.
The pipeline is clearly and summarised shown in~\figref{fig:3-pox-wf}. \\ 
To account for the repeated \acp{ITR} at the ends of the poxvirus genome, the workflow is based on a tiled amplicon approach. During the first steps, the reads of the two pools from each genome half are processed individually as half genomes. Input data for the workflow are two distinct collections of reads from \textit{pool1} and \textit{pool2}, sourced from the sequencing with two libraries; the used primer scheme in \ac{BED} file format that contains an indicator for \textit{pool1} or \textit{pool2} in the \textit{SCORE} column, and a reference sequence that is used for mapping. 

\begin{figure}[ht!]
	\includegraphics[width=0.92\textwidth]{media/3-pox.pdf}
	\caption{Simplified poxvirus genomic analysis workflow for ampliconic Illumina-sequenced data.}
	\label{fig:3-pox-wf}
\end{figure}
As a first step, (1) the provided reference sequence is prepared for the mapping of the two read pools. Hence, the primer scheme is needed to determine the exact start and end position of the pools so that the remaining bases are N-masked. For mapping \textit{pool1} against the full-length reference, the second half of the reference sequence is N-masked and therefore the interval for the remaining bases is constructed as a text parameter. The masking starts at the minimal start position of the first primer of \textit{pool2}. If the pools and primers are of similar size, this position is in the middle part of the reference sequence. It is important that this position that separates the pools is between the \acp{ITR} so the individual mappings of each pool only contain one \ac{ITR}. Accordingly for the mapping of \textit{pool2}, the interval of the remaining bases is constructed by taking the maximal end position of the \textit{pool1} primers and the full length of the reference sequence so that the masking of the first half can be conducted. The construction of the text parameter in the correct input format is done by multiple Galaxy-specific text-processing tools.\\% and can be looked up in the Supplementary~\tabref{tab:aiv-tools-steps}.
Using this approach, it is ensured that the \acp{ITR} are unambiguously mapped and coverage statistics are expressive, which would not be the case if mapping would be performed on the full-length reference and reads from the \ac{ITR} regions could be mapped to either one \ac{ITR}. \\
The workflow is designed to process multiple samples in one run, thus for better comparison the samples of the second pool are sorted by the order of how they are listed in \textit{pool1}. Before mapping, (2) the reads of both pools are preprocessed with \texttt{fastp} to automatically trim Illumina-specific polyG tails of the reads. The following (3) mapping step with \texttt{BWA-MEM} takes the corresponding masked reference sequence for each genome-half. A statistics report for each alignment is generated using \texttt{Samtools stats} and allows the user to inspect the mapping quality and coverage. The alignments are (4) filtered for quality with \texttt{Samtools view} to keep reads with a minimum length of 20 and only properly paired and mapped reads. Additionally, the pool identifiers (\textit{pool1/pool2}) are prepended to the sample names so that using external software to check variants, the pool and sample identification is maintained and unambiguous. In the next step (5), the two alignments are merged while retaining the identifiers for each sample and pool. For the full-length mapping, a coverage report is generated with \texttt{QualiMap BamQC} so that the \acp{ITR} and the part where the mappings are merged can be inspected. The mean coverage depth is an important standard parameter when performing \ac{NGS}. It indicates how often each base occurs on average in the individual reads. For smaller segments or amplicon-based data, checking the depth of coverage in each region is crucial as it provides information on how close the sequenced sample is to the reference sequence selected for mapping. Low coverage indicates incorrect mapping due to many genetic differences. Therefore, coverage plots are given for each sample. \\
(6) Primer-trimming with \texttt{iVar trim} removes the loose primer ends and cleans the alignment for the consensus sequence construction. The (7) consensus sequence is called with \texttt{iVar consensus} and a 10-fold minimum depth. For this step, the user can either use provided default settings (minimum quality score to count base: 20, minimum allele frequency threshold to call \ac{SNV}: 0.7, minimum allele frequency to call indel: 0.8) or enter their own values before starting the workflow. These settings yield for the minimum of ten sequenced reads per base in coverage. With the final combined consensus sequence in FASTA format for each input sample, any downstream analyses can be started. \\
%The workflow with a complete list of the 47 steps, used tools with version number, settings, outputs and connections between the tools is provided in Supplementary~\tabref{tab:pox-tools-steps}. 

\subsection{AIV Illumina Workflow}\label{sec:aiv-wf}
We propose a fully automated pipeline for the analysis with a reference-based mapping approach of Illumina-sequenced paired-end reads from avian influenza samples. The workflow is integrated in the Galaxy platform and is available with all related material via links provided in Supplementary~\secref{sec:apx-aiv-links}. Furthermore, to the best of our knowledge this pipeline is the first ready-to-use workflow that uses a hybrid reference sequence for a fast mapping and provides various outputs for downstream analyses. It is designed to take one input sample at a time and besides a summarising results report, the outputs of the analysis steps can be used for further research based on the user's interest. The workflow is outlined in~\figref{fig:3-aiv-wf}, where the nine main steps of the workflow are visualised. A link to the full workflow of 48 steps with the tools, tool version and settings in \textit{.cwl} and Galaxy-specific \textit{.ga} format can be found in Supplementary~\secref{sec:apx-aiv-links}. \\
One novelty of the workflow is the consideration of the different segments of the influenza virus genome in the reference sequence. After uploading paired-end reads and a reference sequence database, the workflow builds a hybrid reference from the given database for each of the segments of the genome. The reference sequence database is described in detail in the subsequent~\secref{sec:3-aiv-ref}. If a user decides to upload their own curated references, it is important to follow the sequence identifier pattern so that the extraction of sequence identifiers in the workflow works as expected: >\textit{segment\_name$\mid$influenza\_strain$\mid$subtype$\mid$accession\_number}. For example, one entry's identifier is >\textit{PB1$\mid$A/duck/Manitoba/1953$\mid$A/H10N7$\mid$KF435047.1} followed by the sequence in the next line. 

\begin{figure}[ht!]
	\includegraphics[width=0.88\textwidth]{media/3-aiv.pdf}
	\caption{Simplified \ac{AIV} genomic analysis workflow for Illumina-\\sequenced data.}
	\label{fig:3-aiv-wf}
\end{figure}

After (1) preprocessing of the reads with \texttt{fastp} to dismiss reads shorter than 30 basepairs, filter out 5' and 3' ends with a mean quality of below Q30 and automatic trimming polyG tails of the Illumina reads, the database of reference sequences is used to (2) find the closest possible reference for each of the segments. The tool \texttt{VAPOR} outputs a table with a scoring based on the weighted graph construction, and should not be confused with the identity of the sequence compared to the reference. As \texttt{VAPOR} is running once per segment but has independent inputs, this step is executed in parallel. \texttt{VAPOR} is a graph-based classifier that maps k-mers to a weighted De Bruijn graph to find sequences from a database that are as similar as possible to the query sequence~\cite{southgate2020influenza}. Benchmarking shows that it runs significantly faster than \ac{BLAST} and default configurations lead to reasonable matches similar to Mash, as long as the given sample is not very different from or novel to the provided sequences in the reference database. \\
Retrieving the highest scoring sequences from the eight \texttt{VAPOR} runs, a hybrid reference sequence is built. To control the statistics of the graph and adapt the configuration, a table with the highest \texttt{VAPOR} scores of each run is generated. \\
The hybrid reference sequence is composed of the eight segments and is used for the third step of the pipeline, (3) mapping with \texttt{BWA-MEM}. The segment names in the hybrid reference genome are truncated and shortened to just the segment identifier. Mapping of the preprocessed reads against the prepared hybrid reference is run with default parameters of \texttt{BWA-MEM}. The \ac{BWA-MEM} algorithm aligns 70-1000 basepairs long reads by seeding alignments with maximal exact matches, and extending the seeds using the affine-gap Smith-Waterman algorithm~\cite{li2013aligning}. After mapping, the resulting \ac{BAM} dataset is (4) quality filtered using \texttt{Samtools view}. Reads with a minimum quality of 20 and only those that are paired and mapped in a proper pair are kept. The alignment and quality results as well as coverage statistics for each segment are reported using \texttt{QualiMap BamQC}. \\
The subsequent steps before generating the consensus sequence of the sample prepare the \ac{BAM} file and deconstruct the mapped reads into a collection of eight datasets and relabel the elements, so that (5) \texttt{iVar consensus} can perform consensus sequence construction in parallel. Per-segment consensus construction is run with a minimum quality score threshold of 20, minimum frequency threshold of 0.7, minimum depth to call consensus of 10, which does not exclude regions with smaller depth than the minimum threshold and uses N instead of ``-'' for regions with less than the minimum coverage. These settings accept any base as the consensus base for a genome position with a base calling quality of 20 or higher in order to avoid false bases that come from sequencing errors. If there is no consensus base to be found with the above thresholds, an N is inserted instead. \\
To place the consensus sequence of the genome segments in a set of samples from the reference sequences to generate phylogenetic tree data, (6) a multiple sequence alignment for a user-specified number of sequences (i.e. determines the size of the resulting phylogenetic trees) is done with \texttt{MAFFT} (Multiple Alignment using Fast Fourier Transform). The consensus sequence is added using \texttt{MAFFT add}. The multiple sequence alignment is also used for (9) a visualisation of SNPs, produced with the \texttt{snipit} tool. It provides a graphical summary of the variations on base-resolution compared to the reference sequence and other close sequences from the reference database. \\
The next step in the pipeline using the consensus sequence is the (7) generation of genome annotation files with \texttt{Prokka}. Because the input sample is a viral genome, the \textit{Kingdom} parameter is set to \textit{Viruses}. With this file, open reading frames can be predicted using other tools and further downstream analyses can be started. \\
(8) Phylogenetic trees for the \ac{HA} and \ac{NA} segments are built using \texttt{IQ-Tree}. The taxonomy of the sample segments visualised in the phylogenetic trees give insight into spatial and temporal spread of the genome. The consensus sequence from the input sample is assigned to the most likely lineage~\cite{minh2020iq}. Trees can be explored by downloading one of the standard tree formats (\textit{.nhx, .mldist} or \textit{.iqtree}) for further analysis, visualisation or using the Galaxy web-interface with other tools. \\
The presented workflow avoids the computationally expensive \textit{de novo} assembly, instead it uses a mapping approach with a dynamically composed reference genome of close sequences for each of the eight influenza segments. This accounts for a high quality mapping and is evaluated in~\chapref{sec:4-aiv}. To control and look up intermediate outputs, quality reports are emitted during the workflow process and after finishing, which can be downloaded as a \ac{PDF} for each workflow run. \\
Due to a variety of possible downstream analyses that can be of a user's interest, the pipeline provides results of the individual steps so that they can be used with other tools as discussed in~\chapref{chap:discussion}.

\subsection{AIV Reference Database}\label{sec:3-aiv-ref}
For reference-based mapping the \ac{AIV} reads, a reference sequence is required. To choose a representative sequence for each of the eight segments of the influenza genome, a database with sequences is used, split into files by segment. The reference database consists of eight FASTA files, one per segment (PB2, PB1/PB1-F2, PA/PA-X, HA, NP, NA, M1/M2, and NS1/NEP), containing multiple full-length sequences per segment.\\
The sequences were downloaded from the \ac{NCBI} Influenza Virus Database in nucleotide FASTA format. In addition, it is ensured that the 56 sequences from \ac{INSaFLU} twhich are provided in their reference database are part of the reference collection. Only full-length sequences with complete coding regions that include start and stop codons are used. Search results from the \ac{NCBI} Influenza Virus Database show that for some few sequences, the segment genome including start and stop codons is encoded, however includes additional sequence artefacts in the front or tail. Therefore, sequences with a larger length of 105\% of the mean segment genome length according to Chauhan et al. (2022) are dismissed. Additionally, short sequences that hold less than 80\% of the mean segment nucleotide count are dismissed. This criterion ensures that a segment can be shorter than the mean length due to deletions, but does not include sequences that are too short to reliably identify and compare with other sequences.\\
Vaccine strains and mixed subtypes are exluded from the results. Duplicate sequences are dismissed and the sequences are prepared so that the header is in the required format, does not contain spaces and has the segment name in the sequence header before the first pipe. Additionally, all sequences containing non-ACTG bases were dismissed. The remaining sequences ensure within-subtype variation by providing many samples of the same subtype in for each segment. Due to the strict criteria, there are not always all eight segments present for one genome. The filtering criteria mentioned above are essential for maintaining the quality and reliability of the data for the \texttt{VAPOR} tool, for which the reference sequences are used as the collection to query the sample reads on. An overview of the resulting reference database and the filter criteria is provided in Supplementary~\tabref{tab:apx-aiv-ref}. The reference collection with a total of 137 507 unique sequences is ready to import into a new history and publicly available on Galaxy EU. Find the link in Supplementary~\secref{sec:apx-aiv-links}. 


\subsection{FMDV Illumina Workflow}\label{sec:fmdv-wf}
\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.9\textwidth]{media/3-fmdv-1-2.pdf}
	\caption{Simplified FMDV workflow (1/2) with \textit{de novo} assembly and BLASTn search.}
	\label{fig:3-fmdv-wf-1}
\end{figure}
\begin{figure}[ht!]
	\centering
	\includegraphics[width=1\textwidth]{media/3-fmdv-2-2.pdf}
	\caption{Simplified \ac{FMDV} workflow (2/2) with reference-based mapping and consensus sequence construction.}
	\label{fig:3-fmdv-wf-2}
\end{figure}

We propose a workflow for the analysis of data from Foot-and-mouth disease virus using Illumina sequencing technology. The workflow is split into two parts and requires action by the user to
The workflow takes multiple samples in a collection and is integrated into the Galaxy platform. Links to the ready-to-use workflows in \textit{.ga} and \textit{.cwl} format can be found in Supplementary~\secref{sec:apx-fmdv-links}. \\
The first part of the workflow starts with (1) preprocessing of the reads using \texttt{fastp}. Reads shorter than 30 base pairs are discarded, and polyG tails of the Illumina reads are trimmed automatically. \\
In order to find the most similar existing sequence that can be used as a reference for mapping, this workflow first includes a \textit{de novo} assembly with \texttt{rnaviralSPAdes}. It is an assembler tailored for \ac{RNA} viral data and was in a specific version developed for the assembly of \ac{SARS-CoV-2} samples. It improves the existing \texttt{SPAdes} assembler by using knowledge about the structure of viral \ac{RNA} genomes~\cite{meleshko2022coronaspades}. The contigs are then (2) filtered by length to dismiss short contigs that represent only fragments of the viral genome. The cut-off is set to almost half the size of the \ac{FMDV} (minimal length 4 kilobases). This allows the subsequent (3) megablast search on the \ac{NCBI} NT database to find similar genomes even in the case of co-infection or recombination. The user is then required to inspect the hits of the megablast search, and to identify the best matching reference genome based on their own criteria, such as coverage and identity. The results may prove plausibility of the sample or reveal the presence of other nucleic material.

The second workflow for \ac{FMDV} genomic analysis is designed for multiple raw reads in a collection that are mapped to the same reference sequence. This is useful in an outbreak scenario where a workflow user has multiple sequenced samples from the same outbreak and seeks to compare the samples, identify similarities and origin of the virus. However, this workflow can be used as a stand-alone pipeline without the first workflow in case the user aims to map the raw reads to a specific reference sequence. After uploading the reference sequence in FASTA format, identified from the megablast search and retrieved via the \ac{NCBI} upload tool (\texttt{NCBI Accession Download}) or from other sources, the workflow runs a (1) preprocessing with \texttt{fastp} to dismiss short reads and to trim polyG tails of the reads. The second step involves (2) mapping of the preprocessed reads to the reference genome using \texttt{BWA-MEM} with default configurations. This step generates a \ac{SAM} file, which is then (3) filtered for quality using \texttt{samtools}. Paired and mapped reads are kept that have a miniml quality of 20. Alignment and quality reports including coverage statistics are generated per sample using \texttt{QualiMap BamQC}. The filtered \ac{SAM} file is then used to generate a consensus sequence for each sample using the (4) \texttt{iVar consensus} tool. This step allows the workflow to generate a high-quality consensus sequence for each sample, which can be used for downstream analyses, such as multiple sequence alignment and phylogenetic analysis. The resulting consensus sequences from all samples are aligned to the reference genome using (5) \texttt{MAFFT}, and the resulting alignment is used to (6) identify \acs{SNP}s with \texttt{snipit}. The workflow produces a summary report of the results of each step and allows the user to investigate the output of each step further for additional research. 
