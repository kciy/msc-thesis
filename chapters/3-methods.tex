\chapter{Materials and Methods}\label{chap:methods}
The challenges in genomic analysis of viral material using \ac{NGS} raw read data are a major motivation for this work. Ready-to-use pipelines that can be executed without deeper biological or bioinformatic knowledge specifically designed for the viral genomes of avian influenza, pox and foot-and-mouth disease are presented below. They run on the Galaxy platform and show that for development of the pipelines, large parts of existing viral genomic analysis pipelines as such for SARS-CoV-2 can be reused and adapted.

\section{Galaxy Platform}\label{sec:galaxy}
Galaxy is a web-based scientific platform that has become a major player in many fields of life sciences and bioinformatics. Founded in 2007, it has provided an emerging amount of resources and tools to empower scientists and researchers to work with biomedical datasets. The platform is free to use and collaborative, as all related codebases are open-sourced on GitHub. Resources on Galaxy cover genomics, metagenomics, transcriptomics, proteomics, drug discovery and non-biology fields like natural language processing and social sciences.\\
Galaxy's primary objective is to make analyses more accessible, reproducible, and easier to communicate among researchers. The platform's distinctive and success is attributed to four core elements: a very active community, public servers, an open-source software ecosystem, and the Galaxy ToolShed. The community adheres to the FAIR practises (Findable, Accessible, Interoperable and Reusable)~\cite{10.1093/nar/gkac247}.

The Galaxy community is thriving, with over 124,000 users who also contribute to subcommunities. The servers for analyses provide access to public datasets and workflows. The open-source software ecosystem ensures automated setup and deployment of all tools and services, making it simple for beginners and professionals to use. The Galaxy ToolShed is a server dedicated to hosting, sharing, and installing tools used on the platform. A Galaxy tool is the abstraction layer that makes external software usable from within Galaxy with a front-end, and lets users start the program with all its parameters and inputs from within Galaxy. Each program that is available as a Galaxy tool is XML-wrapped to make dependency requirements, parameter and data inputs and other settings possible via the Galaxy web-interface. \\ 
Galaxy workflows are a key feature that allow the user to stack tools in a chain and to configure them so that the workflow user only has to upload or enter data for the input fields. The automated subsequent order and execution of tools in a workflow is used for modular, longer analyses that are executed repeatedly. Each user has a default of 250 GB disk space allocated on the three main public servers to run computations. \\
Workflows that are available on and accepted by the \ac{IWC} on GitHub are conform with the community's best practise standards and tested on the latest Galaxy release. Dockstore for availability in the U.S. and WorkflowHub for EU users publish the \ac{IWC} workflows and guarantee the availability in Docker-based environments and on the workflow collaborative WorkflowHub~\cite{o2017dockstore, goble2021implementing}.

Important contributions of Galaxy, as stated by the Galaxy Community (2022), include Vertebrate Genome Project assembly workflows and research collaborations about \ac{SARS-CoV-2}. Another toolkit leveraged in Galaxy is Galaxy-ML, a set of tools that form a suite for analyses based on machine learning. With growing publicity, more topics are covered by and moved to Galaxy. It has contributed to over 5,700 scientific publications and has many tutorials available for researchers to use. \\
The Galaxy platform is continuously enhanced, and it still attracts around 2,000 new users every month, indicating its quality and significance. The team and infrastructure of Galaxy initially come from the Nekrutenko lab in the Center for Comparative Genomics and Bioinformatics at Penn State, the Taylor lab at Johns Hopkins University, and the Goecks Lab at Oregon Health \& Science University. There are 138 public servers available worldwide as of 2023, while the three most prominent general-purpose server instances are hosted by teams at University of Freiburg, Germany, for \href{https://usegalaxy.eu/}{UseGalaxy.eu}, Texas Advanced Computing Center for \href{https://usegalaxy.org/}{UseGalaxy.org} and Genomics Virtual Laboratory, formerly at the University of Queensland for \href{https://usegalaxy.org.au/}{UseGalaxy.org.au}. These three public servers are synchronised in a subset of reference tools~\cite{10.1093/nar/gkac247}. \\
The platform serves as a public infrastructure that can be used in many different contexts and by professionals from all fields and backgrounds. It therefore is very suitable for offering publicly available and transparent resources for surveillance of diseases.

\section{SARS-CoV-2 Workflow}
The \ac{COVID-19} pandemic motivated many researchers to study and develop analysis workflows of \ac{SARS-CoV-2} sequencing data. In the \ac{IWC} repository, there are seven workflows available and ready to use on Galaxy for the different kind of \ac{NGS} data (ONT/Illumina) and with varying objectives (variant calling/variation reporting/consensus construction). Specifically for Illumina ARTIC reads, a workflow for genomic analysis based on the \texttt{iVar} suite has been released~\cite{iwc2021covidivar}. It is conceptually similar to other existing pipelines outside of Galaxy, written in Nextflow, Snakemake and \ac{WDL}. The workflow for ampliconic Illumina paired-end reads consists of the following steps: (1) read adapters are trimmed with \texttt{fastp} and (2) mapped to a reference genome with \texttt{BWA-MEM}. The alignment is (3) quality filtered using \texttt{Samtools view}, keeping the reads with a minimum length of 20 and only if they are mapped and properly paired. After generation of quality and coverage reports, (4) \texttt{iVar trim} is run with the primer scheme to cut out the primers from the filtered alignment. The cleaned alignment file is processed (5) with \texttt{iVar consensus} to call the consensus sequence and (6) with \texttt{iVar variants} to call variants. The resulting output files are used for variant annotation, phylogenetic assignment of the outbreak lineages and clade assignment. The workflow skeleton is depicted in~\figref{fig:3-sars-wf}. 

\begin{figure}[h!]
	\includegraphics[width=0.95\textwidth]{media/3-sars-cov-2.pdf}
	\caption{Simplified SARS-CoV-2 analysis workflow for ampliconic Illumina-sequenced data.}
	\label{fig:3-sars-wf}
\end{figure}

This workflow is designed for the specific attributes of the \ac{SARS-CoV-2} genome, however most viral genomes can be analysed on genomic level in similar ways. Accounting for the genomic structure and composition of each virus, analysis workflows for poxviruses, avian influenza virus and foot-and-mouth disease virus are developed in this work, reusing components of the described \ac{SARS-CoV-2} workflow. The requirements for the viruses and the workflows are described below, before the developed workflows are examined.

\section{Workflow Requirements}
To account for the distinct attributes of the examined viruses, automated pipelines used to achieve whole-genome insights from raw reads must be tailored to the specific attributes of the virus being examined. The requirements for each workflow are explained below.

\subsubsection{Requirements for Poxvirus Analysis Workflow}
As explained in~\secref{sec:2-pox}, the genome of most poxviruses is bound by identical sequences located at the termini of the genome. It is shown that the size of such differs for some poxviruses like rabbitpox and vaccinia virus, while mpox, cowpox and capripoxviruses have shorter \acp{ITR}~\cite{wittek1978inverted}. For a whole-genome reconstruction from \ac{HTS}-generated reads, alignment algorithms look for the unambiguous location of a read to find the most agreed position for a complete alignment. Since there is no unambiguous position for repeated identical sequences neither in reference-based mapping approaches nor \textit{de novo} assembly, a new approach has to be used so that the two \acp{ITR} are not aligned in the same run, but separately to constitute disambiguity. Therefore, we use a method that splits the sequencing reads into two parts, separating the identical sequences and running alignment algorithms for each of the splits. To build the full-length genome, the alignments need to be ``glued'' back together. To ensure the reads to be mapped in the appropriate and not in the wrong \ac{ITR}, the reads need to be sequenced in two pools with two sequencing libraries. A similar tiling amplicon protocol has been described by Mathijs et al. and the ARTIC network for \ac{SARS-CoV-2} data~\cite{tyson2020improvements, mathijs2022robust}. \\
As a consequence, a requirement for a reference-based surveillance of the genomics of poxviruses is the availability of the primer scheme that was used for the split amplicon-based sequencing with an Illumina sequencer. Working with Illumina-generated NGS data, the workflow necessitates a quality control and trimming of the reads to remove sequencing artefacts and adapters. The \ac{BED} file containing the primers, their positions and the pool identifier is essential for the correct linking of the alignments when splitting the pipeline into two parts and merging them back together. \\
Mapping of each genome-half that each contains one \ac{ITR} requires a reference sequence, which is a compulsory workflow input. Since poxviruses have low mutation rates in general, a fixed reference sequence accounts for a nearly unambiguous mapping and consensus sequence. \\
Apart from the split approach with a masked reference sequence for alignment, the poxvirus reads can be processed in the same way as \ac{SARS-CoV-2} reads. In the \ac{SARS-CoV-2} workflow, clade and lineage assignment, with \texttt{Nextclade} and \texttt{Pangolin} respectively, work with \ac{SARS-CoV-2} specific databases. Although the tools are designed to work with the \ac{SARS-CoV-2} genome, the \texttt{Nextclade} tool is adapted and expanded to work with other viruses (mpox, Influenza A H1N1 and H3N2 HA gene, Influenza B Victoria and Yamagata HA), however not suitable for undetermined poxvirus genus members~\cite{aksamentov2021nextclade}.

\subsubsection{Requirements for AIV Analysis Workflow}
The main objectives of surveillance of \ac{AIV} on the genetic level are to get phylogenetic insights and to check for mutations or new variants that occur in the \ac{HA} and \ac{NA} proteins as a consequence of reassortment. \\
A pipeline for an avian influenza virus sample that builds a consensus sequence requires a reference sequence that it can align the NGS reads to. For an Illumina-based workflow, preprocessing is crucial to ensure reliable results working with the reads. Quality filtering and trimming must be included in the beginning of the workflow. A main caveat of many existing pipelines for \ac{AIV} genomic analysis is the user's choice of reference sequence, since it is an arbitrary selection and has a direct impact on the alignment. Another, computationally very expensive approach would be assembly which does not require a reference sequence. Since the influenza segments can have very similar regions at the segment's ends and mapping is computationally faster than assembly, a reference-guided mapping method is favoured for the analysis of \ac{AIV} samples due to the genome size and high mutation rates of \ac{AIV}. The goal is to use a reference that is representative of the sample being analysed. In the \ac{SARS-CoV-2} pipeline, it is recommended to use a reference genome from a recent \ac{SARS-CoV-2} strain. For avian influenza virus, multiple reference sequences exist depending on the strain and subtype, however this information only helps for the reference selection if the strain or subtype of the sequenced sample is known. Additionally, avian influenza viruses tend to reassort during replication and one sample may match with different possible reference sequences for the different segments. Taking a single reference for mapping, a possibly new reassortment event may not be discovered. Hence, a dynamic approach that is sensitive enough for the segmented structure of the \ac{AIV} genome is needed to pick a representative reference and to relieve the user from taking the complex choice of reference. A search tool like \texttt{VAPOR} could help identifying close reference sequences based on the input reads by looking up a large user-defined database of sequences. The diversity of \ac{HA} and \ac{NA} segments' sequences is significant enough to make it challenging to map sequenced reads to a single, full-length influenza A reference sequence. Although an approach that takes any (maybe imperfect) reference strain may be effective for the other six segments, the mapping software would frequently be unable to achieve sufficiently plausible matches for sequenced reads of the \ac{HA} and \ac{NA} segments to continue with the analysis. By introducing a method that finds the best reference sequence from a database before the actual alignment, the expensive assembly step is avoided, the user is not required to choose an arbitrary reference and mapping to a suitable reference with minimal bias can finally be performed. \\
Compared to analyses with genomes such as \ac{SARS-CoV-2} and due to the segmented structure of the \ac{AIV} genome, duplicates among the mapped reads of the \ac{AIV} sample should not be dismissed as they are in the \ac{SARS-CoV-2} workflow, but kept for maintaining a reasonable high coverage for the further analysis. Downstream analyses for phylogenetic placing are useful for the \ac{HA} and \ac{NA} genes to trace viral origins and consider relations to similar strains, as well as visual summaries of \acp{SNP} for identification of genetic variation in different regions.

\subsubsection{Requirements for FMDV Analysis Workflow}
Genomic analysis of the viral \ac{FMDV} \ac{RNA} genome requires a workflow that accounts for its high mutation rate. Aligning raw Illumina-sequenced reads requires quality control in a preprocessing step to remove sequencing platform specific adapters and dismiss reads with low quality. For alignment of the reads to construct a consensus sequence, mapping to a reference sequence or assembly are considered. Finding a representative reference sequence from a database with many sequences, for \ac{FMDV} reads this approach would regularly fail due to the very high mutation rate and ensuing large differences between the query reads and the database sequences. Therefore, a different approach to find a suitable reference sequence for mapping is required. Since the \ac{FMDV} genome is relatively short with approximately 8.3 kilobases, a \textit{de novo} assembly takes only little amount of computational resources for a run. This is due to less contigs to assemble and fewer gaps to fill during assembly, and usually more high coverage regions that facilitate the assembler to find long contigs. The overall complexity of assembly is highly reduced with short genome lengths and therefore increases efficiency of assembly.\\
A \textit{de novo} assembly of the \ac{FMDV} reads to avoid an arbitrarily chosen reference sequence with a subsequent \ac{BLAST}n search in the nucleotides database is one method to find similar sequences that allow for a high-quality mapping and consensus sequence construction.\\
Additionally, the workflow should include steps for quality control, including the removal of low-quality reads and the identification and removal of potential contaminants or other sources of error. Finally, a workflow for \ac{FMDV} genomic analysis should accommodate Illumina-sequenced data and be able to scale up for working with multiple samples at a time.

\section{Workflow Development}
The developed Galaxy workflows for poxviruses, \ac{AIV} and \ac{FMDV} that account for the genomic structure of each virus and the \ac{NGS} approaches are described below.

\subsection{Poxvirus Illumina Workflow}\label{sec:pox-wf}
The newly designed Galaxy workflow for Illumina-sequenced poxvirus samples with a tiling amplicon approach is available on WorkflowHub, Dockstore and on \ac{IWC} to use on Galaxy EU. Links can be found in Supplementary~\secref{sec:apx-pox-links}. \\
This workflow is the first public pipeline for ampliconic Illumina-sequenced data that provides a ready-to-use infrastructure for genomic analysis of poxviruses with ampliconic data that were sequenced in two pools. It aims at constructing the full genome from ampliconic Illumina-sequenced reads and providing alignment files, sample-specific consensus sequences and intermediate results and reports that give insights into reads, mapping quality and mapping coverage. The pipeline is clearly shown in its structural elements in~\figref{fig:3-pox-wf}. \\ 
To account for the repeated \acp{ITR} at the ends of the poxvirus genome, the workflow is based on a tiled amplicon approach that separates the \acp{ITR} to ensure unambiguous mapping of reads. Therefore, the workflow requires the input reads in two sequencing pools that each represent one half of the genome. During the first steps, the reads of the two pools are processed individually as half genomes. Input data for the workflow are two distinct collections of reads from \textit{pool1} and \textit{pool2}, sourced from the sequencing with two libraries; the used primer scheme in \ac{BED} file format that contains an indicator for \textit{pool1} or \textit{pool2} in the \textit{SCORE} (5th) column; and a reference sequence that is used for mapping which can be retrieved from the \ac{NCBI} reference sequence database depending on the genus of the sequenced sample. 

\begin{figure}[ht!]
	\includegraphics[width=0.92\textwidth]{media/3-pox.pdf}
	\caption{Simplified poxvirus genomic analysis workflow for ampliconic Illumina-sequenced data.}
	\label{fig:3-pox-wf}
\end{figure}

As a first step, (1) the provided reference sequence is prepared for the mapping of the two read pools. Hence, the primer scheme is needed to determine the start and end position of the two pools so that the remaining bases can be N-masked. For mapping \textit{pool1}, which accounts for the first half of primers against the full-length reference, the second half of the reference sequence is N-masked and therefore the interval for the remaining bases is constructed as a text parameter for further workflow logic. The N-masking of the reference starts at the minimal start position of the first primer of \textit{pool2}. If the pools and amount of primers are of similar size, this position is in the middle region of the reference sequence. It is important that this position, separating the pools, is in between the two \acp{ITR} so the individual mappings of each pool only contain one \ac{ITR}. Accordingly for the mapping of \textit{pool2}, the interval of the remaining bases is constructed by taking the maximal end position of the \textit{pool1} primers and the full length of the reference sequence as an end position so that the masking of the first half can be conducted. The construction of the text parameter in the correct input format is done by multiple Galaxy-specific text-processing tools.\\
Using this approach, it is ensured that the \acp{ITR} are unambiguously mapped and coverage statistics are expressive, which would not be the case if mapping would be performed on the full-length reference and reads from the \ac{ITR} regions could be mapped to either one \ac{ITR}. \\
The poxvirus workflow is designed to process multiple samples in one run. The workflow requires the raw reads to be uploaded in two distinct collections, one for \textit{pool1} and one for \textit{pool2}, each containing the reads for potentially multiple samples. For better comparison during the workflow, the samples in the second reads pool collection are sorted by the order of how they are listed in \textit{pool1}.\\
Before mapping, (2) the reads of both pools are preprocessed with \texttt{fastp} to automatically trim Illumina-specific polyG tails of the reads and remove sequencing adapters with default settings of \texttt{fastp} to ensure further quality filtering. 
The following (3) mapping step with \texttt{BWA-MEM} takes the corresponding masked reference sequence for each genome-half as explained. A statistics report for each alignment is generated using \texttt{Samtools stats} and allows the user to inspect the mapping quality and coverage of the alignment. Next, the alignments are (4) filtered for quality using \texttt{Samtools view} to keep reads with a minimum length of 20 and only properly paired and mapped reads. Additionally, the pool identifiers (\textit{pool1/pool2}) are prepended to the sample names so that using external software to check for variants, the pool and sample identification is maintained and unambiguous for the user. In the next step, (5) the two alignments are merged while still retaining the identifiers for each sample and pool. For the full-length mapping, a coverage report is generated with \texttt{QualiMap BamQC} which allows the inspection of the \acp{ITR} and to examine the part where the mappings are merged together. The mean coverage depth is an important standard parameter when performing \ac{NGS}. It indicates how often each base occurs on average in the individual reads. For smaller segments or amplicon-based data, checking the depth of coverage in each region is crucial as it provides information on how close the sequenced sample is compared to the reference sequence that was selected for mapping. Low coverage of an alignment indicates incorrect mapping due to genetic differences. Therefore, coverage plots are provided in the workflow for each sample. \\
To prepare the alignment for consensus sequence construction, (6) primer-trimming with \texttt{iVar trim} removes the loose primer ends. The (7) consensus sequence is called with \texttt{iVar consensus} and a 50-fold minimum depth. For this step, the user can either use provided default settings (minimum quality score to count base: 20, minimum allele frequency threshold to call \ac{SNV}: 0.7, minimum allele frequency to call indel: 0.8) or enter their own values before starting the workflow. These settings yield for the minimum of 50 sequenced reads per base in coverage. With the final combined consensus sequence in FASTA format for each input sample, further downstream analyses can be started after finishing the workflow.

\subsection{AIV Illumina Workflow}\label{sec:aiv-wf}
We designed a fully automated pipeline for the analysis with a reference-based mapping approach of Illumina-sequenced paired-end reads from avian influenza samples. The workflow is integrated in the Galaxy platform and is available with all related material via links provided in Supplementary~\secref{sec:apx-aiv-links}. Furthermore, to the best of our knowledge this pipeline is the first ready-to-use workflow that uses a hybrid reference sequence for a fast mapping and provides various outputs for downstream analyses. It is designed to take one input sample at a time and besides a summarising results report, the outputs of the analysis steps can be used for any consecutive research based on the user's interest. The \ac{AIV} workflow is outlined in~\figref{fig:3-aiv-wf}, where the nine main steps of the workflow are visualised. A link to the full workflow and its supplementary material can be found in Supplementary~\secref{sec:apx-aiv-links}. \\
One novelty of our \ac{AIV} workflow is the consideration of the different segments of the influenza virus genome in the composition of the reference sequence. After uploading paired-end reads and a reference sequence database, the workflow builds a hybrid reference from the database for each of the genome segments. The reference sequence database is described in detail in the subsequent~\secref{sec:3-aiv-ref}. If a user decides to upload their own curated references, it is important to follow the sequence identifier pattern so that the extraction of sequence identifiers in the workflow works as expected: >\textit{segment\_name$\mid$influenza\_strain$\mid$subtype$\mid$accession\_number}. Spaces must be avoided. For instance, one entry's identifier is >\textit{PB1$\mid$A/duck/Manitoba/1953$\mid$A/H10N7$\mid$KF435047.1} followed by the nucleotide sequence in the next line. 

\begin{figure}[ht!]
	\includegraphics[width=0.88\textwidth]{media/3-aiv.pdf}
	\caption{Simplified \ac{AIV} genomic analysis workflow for Illumina-sequenced data.}
	\label{fig:3-aiv-wf}
\end{figure}

The \ac{AIV} workflow takes the reference sequences in datasets split by segment and the paired-end Illumina-sequenced reads, and an additional numeric parameter to determine the size of the produced phylogenetic tree. After (1) preprocessing of the reads with \texttt{fastp} with default quality trimming options, and additionally to dismiss reads shorter than 30 bp, filter out 5' and 3' ends with a mean quality of below Q30 and automatic trimming of polyG tails of the Illumina reads, the database of reference sequences is used to (2) find the closest possible reference for each of the segments. The tool \texttt{VAPOR} outputs a table with a scoring based on the weighted graph construction, and should not be confused with the identity of the sequence compared to the reference. As \texttt{VAPOR} is running once per segment yet with independent inputs, the eight jobs are executed in parallel and do not depend on each other's outputs. \texttt{VAPOR} is a graph-based classifier that maps k-mers to a weighted De Bruijn graph to find sequences from a database that are as similar as possible to the query sequence~\cite{southgate2020influenza}. Benchmarking shows that it runs significantly faster than \ac{BLAST} and default configurations lead to reasonable matches similar to Mash, as long as the given sample is not very different from or novel to the provided sequences in the reference database. \\
Retrieving the highest scoring sequences from the eight \texttt{VAPOR} runs, an integral part of the workflow is to build a hybrid reference sequence used for mapping. To inspect the statistics of the graph and adapt the configuration, a table with the highest \texttt{VAPOR} scores of each run is generated and visible in the workflow history on Galaxy. \\
The hybrid reference sequence is composed of the eight segments and is used as the reference sequence in the third step of the pipeline, (3) mapping with \texttt{BWA-MEM}. The segment names in the hybrid reference genome are truncated and shortened to just the segment identifier. Mapping of the preprocessed reads against the prepared hybrid reference is run with default parameters of \texttt{BWA-MEM}. The \ac{BWA-MEM} algorithm aligns 70 to 1000 bp long reads by seeding alignments with maximal exact matches, and extending the seeds using the affine-gap Smith-Waterman algorithm~\cite{li2013aligning}. After mapping, the resulting \ac{BAM} dataset is (4) quality filtered using \texttt{Samtools view}. Reads with a minimum quality of 20 and only those that are paired and mapped in a proper pair are kept. The alignment and quality results as well as coverage statistics for each segment are reported using \texttt{QualiMap BamQC}. \\
The subsequent steps before generation of the consensus sequence from the reads alignment prepare the \ac{BAM} file and deconstruct the mapped reads into a collection of eight datasets by relabelling the elements so that (5) \texttt{iVar consensus} can perform consensus sequence construction. Per-segment consensus construction is run with a minimum quality score threshold of 20, minimum frequency threshold of 0.7, minimum depth to call consensus of 10, which does not exclude regions with smaller depth than the minimum threshold and uses N instead of ``-'' for regions with less than the minimum coverage. These settings accept any base as the consensus base for a genome position with a base calling quality of 20 or higher in order to avoid false bases that come from sequencing errors. If there is no consensus base to be found with the above criteria, an N is inserted instead. \\
To place the consensus sequence of the genome segments in a set of samples from the reference sequences to generate phylogenetic tree data, (6) a multiple sequence alignment for a user-specified number of sequences that determines the size of the resulting phylogenetic trees is done with \texttt{MAFFT} (Multiple Alignment using Fast Fourier Transform). The consensus sequence is added using \texttt{MAFFT add}. The multiple sequence alignment is also used for (9) a visualisation of SNPs, produced with the \texttt{snipit} tool. It provides a graphical summary of the mutations on base-resolution by comparing the consensus sequence to other close sequences from the reference database. These sequences are selected from the top hits that resulted in the \texttt{VAPOR} run and therefore are suitable to flag up possible mutations or mis-aligned consensus bases in the consensus sequence of each influenza segment. \\
The next step in the pipeline using the consensus sequence is the (7) generation of genome annotation files with \texttt{Prokka}. Because the input sample is a viral genome, the \textit{Kingdom} parameter is set to \textit{Viruses}. With this file, open reading frames can be predicted using other tools and further downstream analyses can be started. (8) Phylogenetic trees for the \ac{HA} and \ac{NA} segments are built using \texttt{IQ-Tree}. The taxonomy of the sample segments visualised in the phylogenetic trees give insight into spatial and temporal spread of the genome. The consensus sequence from the input sample is assigned to the most likely lineage~\cite{minh2020iq}. Trees can be explored by downloading one of the standard tree formats (\textit{.nhx, .mldist} or \textit{.iqtree}) for further analysis, visualisation or using the Galaxy web-interface with visualisation tools. \\
The presented \ac{AIV} workflow avoids the computationally expensive \textit{de novo} assembly, instead uses a mapping approach with a dynamically composed reference genome of close sequences for each of the eight influenza segments. This accounts for a high quality mapping and is evaluated in~\chapref{sec:4-aiv}. To trace the individual steps and look up intermediate outputs, quality reports are emitted during the workflow process and after finishing, which can be downloaded as a PDF for each workflow run. Due to a variety of possible downstream analyses that can be interesting for a user, our workflow provides results of the individual steps which can be used with various other tools.

\subsubsection{AIV Reference Database}\label{sec:3-aiv-ref}
For reference-based mapping of the \ac{AIV} reads in the \ac{AIV} workflow, a reference sequence is required. To choose a representative sequence for each of the eight segments of the influenza genome, a database with sequences is used, split into files by segment. The reference database consists of eight FASTA files, one per segment (PB2, PB1/PB1-F2, PA/PA-X, HA, NP, NA, M1/M2, and NS1/NEP), containing multiple full-length sequences per segment.\\
The sequences were downloaded from the \ac{NCBI} Influenza Virus Database in nucleotide FASTA format. In addition, it is ensured that the 56 sequences from \ac{INSaFLU} which are provided in their reference database are part of the reference collection. Only full-length sequences with complete coding regions that include start and stop codons are used. Search results from the \ac{NCBI} Influenza Virus Database show that for some few sequences, the segment genome including start and stop codons is encoded, however includes additional sequence artefacts possibly from other segments in the front or tail. Therefore, sequences with a length of more than 105\% of the mean segment genome length according to Chauhan et al. (2022) are dismissed. Similarly, short sequences that hold less than 80\% of the mean segment nucleotide count are dismissed. This criterion ensures that a segment can be shorter than the mean length due to deletions, yet does not include sequences that are too short to reliably identify and compare with other sequences.\\
Vaccine strains and mixed subtypes are exluded from the results. Duplicate sequences are dismissed and the sequences are prepared so that the header is in the required format, does not contain spaces and has the segment name in the sequence header before the first pipe. Additionally, all sequences containing non-ACTG bases were dismissed. The remaining sequences ensure within-subtype variation of influenza strain A sequences by providing multiple sequences of the same subtype for each segment. Gene subtypes that occur only in bats as H17, H18, N10 and N11 do, are dismissed from the reference collection~\cite{tong2013new}. Due to the strict criteria, there are not always all eight segments present for one genome. The filtering criteria mentioned above are essential for maintaining the quality and reliability of the data for the \texttt{VAPOR} tool, for which the reference sequences are used as the collection to query the sample reads on. An overview of the resulting reference database and the filter criteria is provided in Supplementary~\tabref{tab:apx-aiv-ref}, as well as an overview in Supplementary~\tabref{tab:apx-aiv-ref-subtypes} of the occurrences of each subtype in the \ac{HA} and \ac{NA} genes. Since the \ac{AIV} is split into its gene segments in each dataset, the reference collection that composes subtypes from the different \ac{HA} subfamilies (1-18) and \ac{NA} (1-11) subfamilies is not required to contain all possible combinations and therefore not all subtypes are required to be present. In the \ac{AIV} workflow, the \texttt{VAPOR} tool looks for \ac{HA} sequences that are highly similar to the query reads, and provides the reference for the specific \ac{HA} subfamily sequence only from the dataset containing \ac{HA} segments. Similarly, the \ac{NA} subfamily is determined by querying the \ac{NA} dataset. This means that in the \ac{HA} \texttt{VAPOR} results and therefore in the reference used for mapping, only the \ac{HA} subfamily part (e.g. H5 from H5N10) determines the \ac{HA} subfamily. Accordingly, the \ac{NA} subfamily is derived by the most similar sequence (e.g. N8 from H3N8) within the \ac{NA} dataset. In combination, the subtype of the sample is derived (e.g. H5N8).
The reference collection with a total of 137 507 unique sequences is ready to import into a new history and publicly available on Galaxy EU. The link is provided in Supplementary~\secref{sec:apx-aiv-links}. 

\subsection{FMDV Illumina Workflow}\label{sec:fmdv-wf}
\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.9\textwidth]{media/3-fmdv-1-2.pdf}
	\caption{Simplified FMDV workflow (1/2) with \textit{de novo} assembly and BLASTn search.}
	\label{fig:3-fmdv-wf-1}
\end{figure}
\begin{figure}[ht!]
	\centering
	\includegraphics[width=1\textwidth]{media/3-fmdv-2-2.pdf}
	\caption{Simplified \ac{FMDV} workflow (2/2) with reference-based mapping and consensus sequence construction.}
	\label{fig:3-fmdv-wf-2}
\end{figure}

We developed a workflow for the genomic analysis of reads from Foot-and-mouth disease virus samples using Illumina sequencing technology. The workflow is split into two single workflow parts and requires the user to take action in the process of reference sequence selection. The \ac{FMDV} workflow takes multiple samples in a collection and is integrated into the Galaxy platform. Links to the two ready-to-use workflows in \textit{.ga} and \textit{.cwl} format can be found in Supplementary~\secref{sec:apx-fmdv-links}. \\

The first part of the workflow accounts for the choice of reference sequence and starts with (1) preprocessing of the reads using \texttt{fastp}. Reads shorter than 30 base pairs are discarded, and polyG tails of the Illumina reads are trimmed automatically. Default settings of \texttt{fastp} account for automatic quality filtering to remove sequencing adapters and unqualified reads by additional quality filters. \\
In order to find the most similar existing sequence that can be used as a reference for mapping, this workflow first includes a \textit{de novo} assembly with \texttt{rnaviralSPAdes}. It is an assembler tailored for short \ac{RNA} viral data and was initially developed in a specific version for the assembly of \ac{SARS-CoV-2} samples. It improves the existing \texttt{SPAdes} assembler by making use of knowledge about the structure of viral \ac{RNA} genomes~\cite{meleshko2022coronaspades}. The \ac{FMDV} contigs, which may be varying in terms of amount of sequences and length of contig, are then (2) filtered by length to dismiss short contigs that represent only fragments of the viral genome. The cut-off is set to almost half the size of the \ac{FMDV} (minimal length 4.0 kilobases). This allows the subsequent (3) megablast search on the \ac{NCBI} NT database to find similar genomes even in the case of co-infection of the sample or recombination within the viral genome. After the \ac{BLAST}n search, the user is required to inspect the hits of the megablast search, and to identify the best matching reference genome based on their own criteria, such as coverage and identity. The resulting sequence that is chosen as a reference may prove plausibility of the sample or reveal the presence of other nucleic material if one of the top \ac{BLAST}n results matches an unexpected virus. To avoid the automatic choice of reference selection by taking the top \ac{BLAST}n match as reference for the following mapping, the workflow is split up. This implies that if a user has their reference sequence in mind independent of the first \ac{FMDV}, the analysis can start directly with the second \ac{FMDV} workflow and by uploading the reference sequence to the Galaxy history.

The second workflow for \ac{FMDV} genomic analysis is designed for multiple raw reads in a collection that are mapped to the same reference sequence. This is useful in an outbreak scenario where a workflow user has multiple sequenced samples from the same outbreak and seeks to compare these samples with each other, identify similarities, relations and origin of the virus. However, this workflow can be used as a stand-alone pipeline without the first workflow in case the user aims to map the raw reads to a specific, arbitrarily chosen reference sequence. After uploading the reference sequence in FASTA format, identified from the megablast search and retrieved via the \ac{NCBI} upload tool (\texttt{NCBI Accession Download}) or from other sources, the workflow runs a (1) preprocessing with \texttt{fastp} to dismiss reads shorter than 30 bp and to trim polyG tails of the reads. The second step involves (2) mapping of the preprocessed reads to the reference genome using \texttt{BWA-MEM} with default configurations. This step generates a \ac{SAM} file, which is then (3) filtered for quality using \texttt{samtools}. Paired and mapped reads are kept that have a minimum quality of 20. Alignment and quality reports including coverage statistics are generated per sample using \texttt{QualiMap BamQC}. The filtered \ac{SAM} file is then used to generate a consensus sequence for each sample using the (4) \texttt{iVar consensus} tool with a minimum quality score threshold of 20, minimum frequency threshold of 0.7, minimum indel frequency threshold of 0.7 and a minimum depth of 10 to call consensus. This step allows the workflow to generate a high-quality consensus sequence for each sample, which can be used for downstream analyses, such as multiple sequence alignment and phylogenetic analysis. The resulting consensus sequences from all samples are aligned to the reference genome using (5) \texttt{MAFFT}, and the resulting alignment is used to (6) identify and visualise \acs{SNP}s with \texttt{snipit}. The \ac{FMDV} workflow produces a summary report of the results of each step and allows the investigation in additional research with the output of each step from within the Galaxy history. 
